{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "プログラム開始\n"
     ]
    }
   ],
   "source": [
    "print('プログラム開始')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import openpyxl\n",
    "from io import StringIO\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.today()\n",
    "today_year = str(today.year)\n",
    "today_month = str(today.month)\n",
    "today_monthz = str(today.month).zfill(2)\n",
    "today_day = str(today.day)\n",
    "today_dayz = str(today.day).zfill(2)\n",
    "today_today = today_year +\"/\"+ today_month +\"/\"+ today_day\n",
    "today_todayz = today_year +\"/\"+ today_monthz +\"/\"+ today_dayz\n",
    "today_today2 = today_year + today_monthz + today_dayz\n",
    "jra = today_year +'/'+ today_year +\"/\"+ today_month +\"/\"+ today_monthz + today_dayz\n",
    "today_tw = today_month + '/' + today_day\n",
    "today_nt = today_monthz + today_dayz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaijou_id_list = ['30', '35', '36', '42',  '43', '44', '45', '46', '47', '48', '50', '51', '54', '55']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_id_list = []\n",
    "for kaijou_id in kaijou_id_list:\n",
    "    race_url = 'https://nar.netkeiba.com/race/shutuba.html?race_id='+today_year+kaijou_id+today_nt+'01'\n",
    "    response = requests.get(race_url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    tables = soup.find_all('table')\n",
    "    # StringIOオブジェクトにHTMLをラップ\n",
    "    html_io = StringIO(str(tables))\n",
    "    # pandasのDataFrameに変換\n",
    "    dfs = pd.read_html(html_io, encoding=response.encoding)\n",
    "    # 最初のテーブルを取得\n",
    "    df = dfs[0]\n",
    "    # データの整形\n",
    "    df = df.T.reset_index(level=0, drop=True).T\n",
    "    if len(df)>1:\n",
    "        for a in range(1,13,1):\n",
    "            race_id_list.append(today_year+kaijou_id+today_nt+str(a).zfill(2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_dict = {\n",
    "    '30':'門別',  '35':'盛岡',  '36':'水沢',  '42':'浦和',  '43':'船橋', '44':'大井',\n",
    "    '45':'川崎',  '46':'金沢',  '47':'笠松',  '48':'名古屋', '50':'園田', '51':'姫路', '54':'高知', '55':'佐賀'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_data_scrape(race_id_list, date):\n",
    "    df_list = []\n",
    "    for race_id in race_id_list:\n",
    "        time.sleep(1)\n",
    "        url = 'https://nar.netkeiba.com/race/shutuba.html?race_id=' + race_id\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        tables = soup.find_all('table')\n",
    "\n",
    "        # StringIOオブジェクトにHTMLをラップ\n",
    "        html_io = StringIO(str(tables))\n",
    "\n",
    "        # pandasのDataFrameに変換\n",
    "        dfs = pd.read_html(html_io, encoding=response.encoding)\n",
    "\n",
    "        # 最初のテーブルを取得\n",
    "        df = dfs[0]\n",
    "\n",
    "        # データの整形\n",
    "        df = df.T.reset_index(level=0, drop=True).T\n",
    "        if len(df) != 0:\n",
    "            html = requests.get(url)\n",
    "            html.encoding = \"EUC-JP\"\n",
    "            soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "\n",
    "            texts = soup.find('div', attrs={'class': 'RaceData01'}).text\n",
    "            texts = re.findall(r'\\w+', texts)\n",
    "            for text in texts:\n",
    "                #if 'm' in text:\n",
    "                #    df['course_len'] = [int(re.findall(r'\\d+', text)[-1])] * len(df) #20211212：[0]→[-1]に修正\n",
    "                if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                    df[\"weather\"] = [text] * len(df)\n",
    "                if text in [\"良\", \"稍重\", \"重\"]:\n",
    "                    df[\"ground_state\"] = [text] * len(df)\n",
    "                if '不' in text:\n",
    "                    df[\"ground_state\"] = ['不良'] * len(df)\n",
    "                # 2020/12/13追加\n",
    "                if '稍' in text:\n",
    "                    df[\"ground_state\"] = ['稍重'] * len(df)\n",
    "                if '芝' in text:\n",
    "                    df['race_type'] = ['芝'] * len(df)\n",
    "                if '障' in text:\n",
    "                    df['race_type'] = ['障害'] * len(df)\n",
    "                if 'ダ' in text:\n",
    "                    df['race_type'] = ['ダート'] * len(df)\n",
    "            df['date'] = [date] * len(df)\n",
    "\n",
    "            # horse_id\n",
    "            horse_id_list = []\n",
    "            horse_td_list = soup.find_all(\"td\", attrs={'class': 'HorseInfo'})\n",
    "            for td in horse_td_list:\n",
    "                horse_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                horse_id_list.append(horse_id)\n",
    "\n",
    "            corse_around = []\n",
    "            table = soup.find('div',class_ ='RaceData01')\n",
    "            #for a in table:\n",
    "            #    b = a.text\n",
    "            #    if '(' in b :\n",
    "            #        c = b.split(')')[0]\n",
    "            #        d = c[2]\n",
    "            #        corse_around.append(d)\n",
    "\n",
    "\n",
    "            df[\"horse_id\"] = horse_id_list\n",
    "            #df['corse_around'] = corse_around* len(df)\n",
    "            #インデックスをrace_idにする \n",
    "            df.index = [race_id] * len(df)\n",
    "            df['競馬場'] = [place_dict[race_id[4:6]]] * len(df)\n",
    "            df['レース'] = [race_id[10:]] * len(df)\n",
    "            df.drop(['印','登録','メモ'],axis=1,inplace=True)\n",
    "            df['厩舎'] = df['厩舎'].str.split(' ', expand=True)[1]\n",
    "            df = df.rename(columns={'厩舎':'調教師'})\n",
    "            df_list.append(df)\n",
    "    try:\n",
    "        df_concat = pd.concat(df_list)\n",
    "    except:\n",
    "        df_concat = pd.DataFrame()\n",
    "    return df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horse_data_scrape(horse_id_list):\n",
    "\n",
    "    #horse_idをkeyにしてDataFrame型を格納\n",
    "    horse_results = []\n",
    "    for horse_id in horse_id_list:\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            session = requests.Session()\n",
    "            url = 'https://db.netkeiba.com/horse/' + horse_id\n",
    "            res = session.get(url, timeout=(3.0, 7.5))\n",
    "            df = pd.read_html(res.content)[1].T\n",
    "            df.columns = df.iloc[0,:].values\n",
    "            df = df[1:].reset_index(drop=True)\n",
    "            session = requests.Session()\n",
    "            url = 'https://db.netkeiba.com/horse/' + horse_id\n",
    "            res = session.get(url, timeout=(3.0, 7.5))\n",
    "            df_1 = pd.merge(pd.read_html(res.content)[2][:1], pd.read_html(res.content)[2][1:2], on=0)\n",
    "            df_1.columns = ['父', '父_父', '父_母']\n",
    "            df_2 = pd.merge(pd.read_html(res.content)[2][2:3], pd.read_html(res.content)[2][3:4], on=0)\n",
    "            df_2.columns = ['母', '母_父', '母_母']\n",
    "            df_concat = pd.concat([df, df_1, df_2], axis=1)\n",
    "            df_concat['horse_id'] = horse_id\n",
    "            df_concat = df_concat.drop('調教師',axis=1)\n",
    "            horse_results.append(df_concat)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    #pd.DataFrame型にして一つのデータにまとめる        \n",
    "    horse_results_df = pd.concat(horse_results)\n",
    "\n",
    "    return horse_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_merge(race_data, horse_data):\n",
    "    df_merge = pd.merge(race_data, horse_data, on='horse_id', how='left')\n",
    "    try:\n",
    "        df_merge = df_merge.drop(['募集情報', 'horse_id'],axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    df_merge = df_merge[['date', '競馬場',  'レース', '馬 番', '生年月日', '馬名', '騎手', '調教師', '馬主']]\n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = openpyxl.Workbook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_id_only_list = []\n",
    "for race_id in race_id_list:\n",
    "    if race_id[4:6] not in race_id_only_list:\n",
    "        race_id_only_list.append((race_id[4:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['36', '44', '46', '47']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_id_only_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202436060401\n",
      "202436060402\n",
      "202436060403\n",
      "202436060404\n",
      "202436060405\n",
      "202436060406\n",
      "202436060407\n",
      "202436060408\n",
      "202436060409\n",
      "202436060410\n",
      "202436060411\n",
      "202436060412\n",
      "202444060401\n",
      "202444060402\n",
      "202444060403\n",
      "202444060404\n",
      "202444060405\n",
      "202444060406\n",
      "202444060407\n",
      "202444060408\n",
      "202444060409\n",
      "202444060410\n",
      "202444060411\n",
      "202444060412\n",
      "202446060401\n",
      "202446060402\n",
      "202446060403\n",
      "202446060404\n",
      "202446060405\n",
      "202446060406\n",
      "202446060407\n",
      "202446060408\n",
      "202446060409\n",
      "202446060410\n",
      "202446060411\n",
      "202446060412\n",
      "202447060401\n",
      "202447060402\n",
      "202447060403\n",
      "202447060404\n",
      "202447060405\n",
      "202447060406\n",
      "202447060407\n",
      "202447060408\n",
      "202447060409\n",
      "202447060410\n",
      "202447060411\n",
      "202447060412\n"
     ]
    }
   ],
   "source": [
    "df_merge_list = []\n",
    "for keibajo in race_id_only_list:\n",
    "    only_race_data_list = []\n",
    "    for race_id in race_id_list:\n",
    "        if keibajo == race_id[4:6]:\n",
    "            only_race_data_list.append(race_id)\n",
    "    race_data = race_data_scrape(only_race_data_list, today_todayz)\n",
    "    if len(race_data) != 0:\n",
    "        horse_data = horse_data_scrape(race_data['horse_id'].unique())\n",
    "        df_merge = data_merge(race_data, horse_data)\n",
    "        df_merge_list.append(df_merge)\n",
    "    else:\n",
    "        print('レースデータがありません。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(today_today2+'.xlsx') as writer:\n",
    "    for i, data in enumerate(df_merge_list):\n",
    "        sheet_name = data['競馬場'][0]\n",
    "        data.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
